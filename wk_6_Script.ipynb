{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Keep walking.', 'Keep moving.', 'Things dont happen on their own.']\n",
      "['Keep', 'walking', '.', 'Keep', 'moving', '.', 'Things', 'dont', 'happen', 'on', 'their', 'own', '.']\n",
      "['Keep', 'walking', '.', 'Keep', 'moving', '.', 'Things', 'dont', 'happen', '.']\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "from nltk.corpus import stopwords,movie_reviews\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "exsent = \"Keep walking. Keep moving. Things dont happen on their own.\"\n",
    "\n",
    "print(sent_tokenize(exsent))\n",
    "word_tokens = word_tokenize(exsent)\n",
    "print(word_tokens)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['films', 'adapted', 'comic', 'books', 'plenty', 'success', ',', 'whether', \"'\", 'superheroes', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'geared', 'toward', 'kids', '(', 'casper', ')', 'arthouse', 'crowd', '(', 'ghost', 'world', ')', ',', \"'\", 'never', 'really', 'comic', 'book', 'like', 'hell', '.', 'starters', ',', 'created', 'alan', 'moore', '(', 'eddie', 'campbell', ')', ',', 'brought', 'medium', 'whole', 'new', 'level', 'mid', \"'\", '80s', '12', '-', 'part', 'series', 'called', 'watchmen', '.', 'say', 'moore', 'campbell', 'thoroughly', 'researched', 'subject', 'jack', 'ripper', 'would', 'like', 'saying', 'michael', 'jackson', 'starting', 'look', 'little', 'odd', '.', 'book', '(', '\"', 'graphic', 'novel', ',', '\"', ')', '500', 'pages', 'long', 'includes', 'nearly', '30', 'consist', 'nothing', 'footnotes', '.', 'words', ',', \"'\", 'dismiss', 'film', 'source', '.', 'get', 'past', 'whole', 'comic', 'book', 'thing', ',', 'might', 'find', 'another', 'stumbling', 'block', 'hell', \"'\", 'directors', ',', 'albert', 'allen', 'hughes', '.', 'getting', 'hughes', 'brothers', 'direct', 'seems', 'almost', 'ludicrous', 'casting', 'carrot', 'top', ',', 'well', ',', 'anything', ',', 'riddle', ':', 'better', 'direct', 'film', \"'\", 'set', 'ghetto', 'features', 'really', 'violent', 'street', 'crime', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', '?', 'ghetto', 'question', ',', 'course', ',', 'whitechapel', '1888', 'london', \"'\", 'east', 'end', '.', \"'\", 'filthy', ',', 'sooty', 'place', 'whores', '(', 'called', '\"', 'unfortunates', '\"', ')', 'starting', 'get', 'little', 'nervous', 'mysterious', 'psychopath', 'carving', 'profession', 'surgical', 'precision', '.', 'first', 'stiff', 'turns', ',', 'copper', 'peter', 'godley', '(', 'robbie', 'coltrane', ',', 'world', 'enough', ')', 'calls', 'inspector', 'frederick', 'abberline', '(', 'johnny', 'depp', ',', 'blow', ')', 'crack', 'case', '.', 'abberline', ',', 'widower', ',', 'prophetic', 'dreams', 'unsuccessfully', 'tries', 'quell', 'copious', 'amounts', 'absinthe', 'opium', '.', 'upon', 'arriving', 'whitechapel', ',', 'befriends', 'unfortunate', 'named', 'mary', 'kelly', '(', 'heather', 'graham', ',', 'say', \"'\", ')', 'proceeds', 'investigate', 'horribly', 'gruesome', 'crimes', 'even', 'police', 'surgeon', \"'\", 'stomach', '.', \"'\", 'think', 'anyone', 'needs', 'briefed', 'jack', 'ripper', ',', \"'\", 'go', 'particulars', ',', 'say', 'moore', 'campbell', 'unique', 'interesting', 'theory', 'identity', 'killer', 'reasons', 'chooses', 'slay', '.', 'comic', ',', \"'\", 'bother', 'cloaking', 'identity', 'ripper', ',', 'screenwriters', 'terry', 'hayes', '(', 'vertical', 'limit', ')', 'rafael', 'yglesias', '(', 'les', 'mis', '?', 'rables', ')', 'good', 'job', 'keeping', 'hidden', 'viewers', 'end', '.', \"'\", 'funny', 'watch', 'locals', 'blindly', 'point', 'finger', 'blame', 'jews', 'indians', ',', ',', 'englishman', 'could', 'never', 'capable', 'committing', 'ghastly', 'acts', '.', 'hell', \"'\", 'ending', 'whistling', 'stonecutters', 'song', 'simpsons', 'days', '(', '\"', 'holds', 'back', 'electric', 'car', '/', 'made', 'steve', 'guttenberg', 'star', '?', '\"', ')', '.', \"'\", 'worry', '-', \"'\", 'make', 'sense', 'see', '.', 'onto', 'hell', \"'\", 'appearance', ':', \"'\", 'certainly', 'dark', 'bleak', 'enough', ',', \"'\", 'surprising', 'see', 'much', 'looks', 'like', 'tim', 'burton', 'film', 'planet', 'apes', '(', 'times', ',', 'seems', 'like', 'sleepy', 'hollow', '2', ')', '.', 'print', 'saw', \"'\", 'completely', 'finished', '(', 'color', 'music', 'finalized', ',', 'comments', 'marilyn', 'manson', ')', ',', 'cinematographer', 'peter', 'deming', '(', \"'\", 'say', 'word', ')', 'ably', 'captures', 'dreariness', 'victorian', '-', 'era', 'london', 'helped', 'make', 'flashy', 'killing', 'scenes', 'remind', 'crazy', 'flashbacks', 'twin', 'peaks', ',', 'even', 'though', 'violence', 'film', 'pales', 'comparison', 'black', '-', '-', 'white', 'comic', '.', 'oscar', 'winner', 'martin', 'childs', \"'\", '(', 'shakespeare', 'love', ')', 'production', 'design', 'turns', 'original', 'prague', 'surroundings', 'one', 'creepy', 'place', '.', 'even', 'acting', 'hell', 'solid', ',', 'dreamy', 'depp', 'turning', 'typically', 'strong', 'performance', 'deftly', 'handling', 'british', 'accent', '.', 'ians', 'holm', '(', 'joe', 'gould', \"'\", 'secret', ')', 'richardson', '(', '102', 'dalmatians', ')', 'log', 'great', 'supporting', 'roles', ',', 'big', 'surprise', 'graham', '.', 'cringed', 'first', 'time', 'opened', 'mouth', ',', 'imagining', 'attempt', 'irish', 'accent', ',', 'actually', \"'\", 'half', 'bad', '.', 'film', ',', 'however', ',', 'good', '.', '2', ':', '00', '-', 'r', 'strong', 'violence', '/', 'gore', ',', 'sexuality', ',', 'language', 'drug', 'content']\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "from nltk.corpus import stopwords,movie_reviews\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "exsent = movie_reviews.words(\"pos/cv000_29590.txt\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [w for w in exsent if not w in stop_words]\n",
    "\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'adapt', 'comic', 'book', 'plenti', 'success', ',', 'whether', \"'\", 'superhero', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'gear', 'toward', 'kid', '(', 'casper', ')', 'arthous', 'crowd', '(', 'ghost', 'world', ')', ',', \"'\", 'never', 'realli', 'comic', 'book', 'like', 'hell', '.', 'starter', ',', 'creat', 'alan', 'moor', '(', 'eddi', 'campbel', ')', ',', 'brought', 'medium', 'whole', 'new', 'level', 'mid', \"'\", '80', '12', '-', 'part', 'seri', 'call', 'watchmen', '.', 'say', 'moor', 'campbel', 'thoroughli', 'research', 'subject', 'jack', 'ripper', 'would', 'like', 'say', 'michael', 'jackson', 'start', 'look', 'littl', 'odd', '.', 'book', '(', '\"', 'graphic', 'novel', ',', '\"', ')', '500', 'page', 'long', 'includ', 'nearli', '30', 'consist', 'noth', 'footnot', '.', 'word', ',', \"'\", 'dismiss', 'film', 'sourc', '.', 'get', 'past', 'whole', 'comic', 'book', 'thing', ',', 'might', 'find', 'anoth', 'stumbl', 'block', 'hell', \"'\", 'director', ',', 'albert', 'allen', 'hugh', '.', 'get', 'hugh', 'brother', 'direct', 'seem', 'almost', 'ludicr', 'cast', 'carrot', 'top', ',', 'well', ',', 'anyth', ',', 'riddl', ':', 'better', 'direct', 'film', \"'\", 'set', 'ghetto', 'featur', 'realli', 'violent', 'street', 'crime', 'mad', 'genius', 'behind', 'menac', 'ii', 'societi', '?', 'ghetto', 'question', ',', 'cours', ',', 'whitechapel', '1888', 'london', \"'\", 'east', 'end', '.', \"'\", 'filthi', ',', 'sooti', 'place', 'whore', '(', 'call', '\"', 'unfortun', '\"', ')', 'start', 'get', 'littl', 'nervou', 'mysteri', 'psychopath', 'carv', 'profess', 'surgic', 'precis', '.', 'first', 'stiff', 'turn', ',', 'copper', 'peter', 'godley', '(', 'robbi', 'coltran', ',', 'world', 'enough', ')', 'call', 'inspector', 'frederick', 'abberlin', '(', 'johnni', 'depp', ',', 'blow', ')', 'crack', 'case', '.', 'abberlin', ',', 'widow', ',', 'prophet', 'dream', 'unsuccess', 'tri', 'quell', 'copiou', 'amount', 'absinth', 'opium', '.', 'upon', 'arriv', 'whitechapel', ',', 'befriend', 'unfortun', 'name', 'mari', 'kelli', '(', 'heather', 'graham', ',', 'say', \"'\", ')', 'proce', 'investig', 'horribl', 'gruesom', 'crime', 'even', 'polic', 'surgeon', \"'\", 'stomach', '.', \"'\", 'think', 'anyon', 'need', 'brief', 'jack', 'ripper', ',', \"'\", 'go', 'particular', ',', 'say', 'moor', 'campbel', 'uniqu', 'interest', 'theori', 'ident', 'killer', 'reason', 'choos', 'slay', '.', 'comic', ',', \"'\", 'bother', 'cloak', 'ident', 'ripper', ',', 'screenwrit', 'terri', 'hay', '(', 'vertic', 'limit', ')', 'rafael', 'yglesia', '(', 'le', 'mi', '?', 'rabl', ')', 'good', 'job', 'keep', 'hidden', 'viewer', 'end', '.', \"'\", 'funni', 'watch', 'local', 'blindli', 'point', 'finger', 'blame', 'jew', 'indian', ',', ',', 'englishman', 'could', 'never', 'capabl', 'commit', 'ghastli', 'act', '.', 'hell', \"'\", 'end', 'whistl', 'stonecutt', 'song', 'simpson', 'day', '(', '\"', 'hold', 'back', 'electr', 'car', '/', 'made', 'steve', 'guttenberg', 'star', '?', '\"', ')', '.', \"'\", 'worri', '-', \"'\", 'make', 'sens', 'see', '.', 'onto', 'hell', \"'\", 'appear', ':', \"'\", 'certainli', 'dark', 'bleak', 'enough', ',', \"'\", 'surpris', 'see', 'much', 'look', 'like', 'tim', 'burton', 'film', 'planet', 'ape', '(', 'time', ',', 'seem', 'like', 'sleepi', 'hollow', '2', ')', '.', 'print', 'saw', \"'\", 'complet', 'finish', '(', 'color', 'music', 'final', ',', 'comment', 'marilyn', 'manson', ')', ',', 'cinematograph', 'peter', 'deme', '(', \"'\", 'say', 'word', ')', 'abli', 'captur', 'dreari', 'victorian', '-', 'era', 'london', 'help', 'make', 'flashi', 'kill', 'scene', 'remind', 'crazi', 'flashback', 'twin', 'peak', ',', 'even', 'though', 'violenc', 'film', 'pale', 'comparison', 'black', '-', '-', 'white', 'comic', '.', 'oscar', 'winner', 'martin', 'child', \"'\", '(', 'shakespear', 'love', ')', 'product', 'design', 'turn', 'origin', 'pragu', 'surround', 'one', 'creepi', 'place', '.', 'even', 'act', 'hell', 'solid', ',', 'dreami', 'depp', 'turn', 'typic', 'strong', 'perform', 'deftli', 'handl', 'british', 'accent', '.', 'ian', 'holm', '(', 'joe', 'gould', \"'\", 'secret', ')', 'richardson', '(', '102', 'dalmatian', ')', 'log', 'great', 'support', 'role', ',', 'big', 'surpris', 'graham', '.', 'cring', 'first', 'time', 'open', 'mouth', ',', 'imagin', 'attempt', 'irish', 'accent', ',', 'actual', \"'\", 'half', 'bad', '.', 'film', ',', 'howev', ',', 'good', '.', '2', ':', '00', '-', 'r', 'strong', 'violenc', '/', 'gore', ',', 'sexual', ',', 'languag', 'drug', 'content']\n"
     ]
    }
   ],
   "source": [
    "#stemming file solution 1\n",
    "#import nltk\n",
    "from nltk.corpus import stopwords,movie_reviews\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "review = movie_reviews.words(\"pos/cv000_29590.txt\")\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [w for w in review if not w in stop_words ]\n",
    "\n",
    "stemmed_words = []\n",
    "\n",
    "for w in filtered_words:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'adapt', 'comic', 'book', 'plenti', 'success', ',', 'whether', \"'\", 'superhero', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'gear', 'toward', 'kid', '(', 'casper', ')', 'arthous', 'crowd', '(', 'ghost', 'world', ')', ',', \"'\", 'never', 'realli', 'comic', 'book', 'like', 'hell', '.', 'starter', ',', 'creat', 'alan', 'moor', '(', 'eddi', 'campbel', ')', ',', 'brought', 'medium', 'whole', 'new', 'level', 'mid', \"'\", '80', '12', '-', 'part', 'seri', 'call', 'watchmen', '.', 'say', 'moor', 'campbel', 'thoroughli', 'research', 'subject', 'jack', 'ripper', 'would', 'like', 'say', 'michael', 'jackson', 'start', 'look', 'littl', 'odd', '.', 'book', '(', '\"', 'graphic', 'novel', ',', '\"', ')', '500', 'page', 'long', 'includ', 'nearli', '30', 'consist', 'noth', 'footnot', '.', 'word', ',', \"'\", 'dismiss', 'film', 'sourc', '.', 'get', 'past', 'whole', 'comic', 'book', 'thing', ',', 'might', 'find', 'anoth', 'stumbl', 'block', 'hell', \"'\", 'director', ',', 'albert', 'allen', 'hugh', '.', 'get', 'hugh', 'brother', 'direct', 'seem', 'almost', 'ludicr', 'cast', 'carrot', 'top', ',', 'well', ',', 'anyth', ',', 'riddl', ':', 'better', 'direct', 'film', \"'\", 'set', 'ghetto', 'featur', 'realli', 'violent', 'street', 'crime', 'mad', 'genius', 'behind', 'menac', 'ii', 'societi', '?', 'ghetto', 'question', ',', 'cours', ',', 'whitechapel', '1888', 'london', \"'\", 'east', 'end', '.', \"'\", 'filthi', ',', 'sooti', 'place', 'whore', '(', 'call', '\"', 'unfortun', '\"', ')', 'start', 'get', 'littl', 'nervou', 'mysteri', 'psychopath', 'carv', 'profess', 'surgic', 'precis', '.', 'first', 'stiff', 'turn', ',', 'copper', 'peter', 'godley', '(', 'robbi', 'coltran', ',', 'world', 'enough', ')', 'call', 'inspector', 'frederick', 'abberlin', '(', 'johnni', 'depp', ',', 'blow', ')', 'crack', 'case', '.', 'abberlin', ',', 'widow', ',', 'prophet', 'dream', 'unsuccess', 'tri', 'quell', 'copiou', 'amount', 'absinth', 'opium', '.', 'upon', 'arriv', 'whitechapel', ',', 'befriend', 'unfortun', 'name', 'mari', 'kelli', '(', 'heather', 'graham', ',', 'say', \"'\", ')', 'proce', 'investig', 'horribl', 'gruesom', 'crime', 'even', 'polic', 'surgeon', \"'\", 'stomach', '.', \"'\", 'think', 'anyon', 'need', 'brief', 'jack', 'ripper', ',', \"'\", 'go', 'particular', ',', 'say', 'moor', 'campbel', 'uniqu', 'interest', 'theori', 'ident', 'killer', 'reason', 'choos', 'slay', '.', 'comic', ',', \"'\", 'bother', 'cloak', 'ident', 'ripper', ',', 'screenwrit', 'terri', 'hay', '(', 'vertic', 'limit', ')', 'rafael', 'yglesia', '(', 'le', 'mi', '?', 'rabl', ')', 'good', 'job', 'keep', 'hidden', 'viewer', 'end', '.', \"'\", 'funni', 'watch', 'local', 'blindli', 'point', 'finger', 'blame', 'jew', 'indian', ',', ',', 'englishman', 'could', 'never', 'capabl', 'commit', 'ghastli', 'act', '.', 'hell', \"'\", 'end', 'whistl', 'stonecutt', 'song', 'simpson', 'day', '(', '\"', 'hold', 'back', 'electr', 'car', '/', 'made', 'steve', 'guttenberg', 'star', '?', '\"', ')', '.', \"'\", 'worri', '-', \"'\", 'make', 'sens', 'see', '.', 'onto', 'hell', \"'\", 'appear', ':', \"'\", 'certainli', 'dark', 'bleak', 'enough', ',', \"'\", 'surpris', 'see', 'much', 'look', 'like', 'tim', 'burton', 'film', 'planet', 'ape', '(', 'time', ',', 'seem', 'like', 'sleepi', 'hollow', '2', ')', '.', 'print', 'saw', \"'\", 'complet', 'finish', '(', 'color', 'music', 'final', ',', 'comment', 'marilyn', 'manson', ')', ',', 'cinematograph', 'peter', 'deme', '(', \"'\", 'say', 'word', ')', 'abli', 'captur', 'dreari', 'victorian', '-', 'era', 'london', 'help', 'make', 'flashi', 'kill', 'scene', 'remind', 'crazi', 'flashback', 'twin', 'peak', ',', 'even', 'though', 'violenc', 'film', 'pale', 'comparison', 'black', '-', '-', 'white', 'comic', '.', 'oscar', 'winner', 'martin', 'child', \"'\", '(', 'shakespear', 'love', ')', 'product', 'design', 'turn', 'origin', 'pragu', 'surround', 'one', 'creepi', 'place', '.', 'even', 'act', 'hell', 'solid', ',', 'dreami', 'depp', 'turn', 'typic', 'strong', 'perform', 'deftli', 'handl', 'british', 'accent', '.', 'ian', 'holm', '(', 'joe', 'gould', \"'\", 'secret', ')', 'richardson', '(', '102', 'dalmatian', ')', 'log', 'great', 'support', 'role', ',', 'big', 'surpris', 'graham', '.', 'cring', 'first', 'time', 'open', 'mouth', ',', 'imagin', 'attempt', 'irish', 'accent', ',', 'actual', \"'\", 'half', 'bad', '.', 'film', ',', 'howev', ',', 'good', '.', '2', ':', '00', '-', 'r', 'strong', 'violenc', '/', 'gore', ',', 'sexual', ',', 'languag', 'drug', 'content']\n"
     ]
    }
   ],
   "source": [
    "#stemming file solution 2\n",
    "#import nltk\n",
    "from nltk.corpus import stopwords,movie_reviews\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "review = movie_reviews.words(\"pos/cv000_29590.txt\")\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [ps.stem(w) for w in review if not w in stop_words ]\n",
    "\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
      "\n",
      "2411\n",
      "\n",
      "Accuracy= 0.826\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     13.5 : 1.0\n",
      "                  finest = True              pos : neg    =     12.9 : 1.0\n",
      "                  seagal = True              neg : pos    =      9.0 : 1.0\n",
      "                  alicia = True              neg : pos    =      9.0 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.6 : 1.0\n",
      "                    lame = True              neg : pos    =      7.0 : 1.0\n",
      "                 freedom = True              pos : neg    =      7.0 : 1.0\n",
      "                   awful = True              neg : pos    =      5.9 : 1.0\n",
      "             wonderfully = True              pos : neg    =      5.9 : 1.0\n",
      "                   patch = True              neg : pos    =      5.8 : 1.0\n",
      "                   inept = True              neg : pos    =      5.4 : 1.0\n",
      "                  superb = True              pos : neg    =      5.3 : 1.0\n",
      "                religion = True              pos : neg    =      5.2 : 1.0\n",
      "                terrific = True              pos : neg    =      5.2 : 1.0\n",
      "                banderas = True              neg : pos    =      5.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#step 1\n",
    "documents = []\n",
    "\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        item = (movie_reviews.words(fileid),category)\n",
    "        documents.append(item)\n",
    "        \n",
    "\n",
    "#step 2             \n",
    "random.shuffle(documents)\n",
    "all_words=[]\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "    \n",
    "#step 3 \n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print(all_words.most_common(15))\n",
    "print(\"\")\n",
    "print(all_words[\"good\"])\n",
    "print(\"\")\n",
    "#print(all_words)\n",
    "\n",
    "#step 4\n",
    "\n",
    "common_words = []\n",
    "for i in list(all_words.most_common(3000)):\n",
    "    common_words.append(i[0])\n",
    "    \n",
    "#step 5 :\n",
    "    \n",
    "def find_features(document):\n",
    "    unique_words_in_document = set(document)\n",
    "    features ={}\n",
    "    \n",
    "    for w in common_words:\n",
    "        features[w] = (w in unique_words_in_document)\n",
    "        \n",
    "    return features\n",
    "\n",
    "#step 6\n",
    "featuresets =[]\n",
    "\n",
    "for(review_words,review_category) in documents:\n",
    "    featuresets.append((find_features(review_words),review_category))\n",
    "    \n",
    "# step 7 \n",
    "\n",
    "training_set = featuresets[:1500]\n",
    "test_set = featuresets[1500:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(classifier,test_set)\n",
    "\n",
    "print(\"Accuracy=\",accuracy)\n",
    "\n",
    "\n",
    "classifier.show_most_informative_features(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
